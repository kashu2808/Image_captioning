{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "from time import time\n",
    "import pickle\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
    "from keras.layers.merge import add\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# example of loading an image with the Keras API\n",
    "from keras.preprocessing.image import load_img\n",
    "from PIL import Image,ImageFile\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = None\n",
    "with open(\"file.txt\",'r') as f:\n",
    "    descriptions= f.read()\n",
    "    \n",
    "json_acceptable_string = descriptions.replace(\"'\",\"\\\"\")\n",
    "descriptions = json.loads(json_acceptable_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(descriptions[\"667626_18933d713e\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for key in descriptions.keys():\n",
    "    for caption in descriptions[key]:\n",
    "        vocab.update(caption.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words=[]\n",
    "for key in descriptions.keys():\n",
    "    for caption in descriptions[key]:\n",
    "        caption=caption.split()\n",
    "        for i in caption:\n",
    "            total_words.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "counter=collections.Counter(total_words)\n",
    "freq_cnt = dict(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in freq_cnt.items():\n",
    "    print(x,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq= sorted(freq_cnt.items(),reverse=True,key=lambda x:int(x[1]))\n",
    "\n",
    "\n",
    "sorted_freq=[x for x in sorted_freq if x[1]>10]\n",
    "total_words = [x[0] for x in sorted_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(total_words))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=\"./Images/\"\n",
    "def preprocess_img(img):\n",
    "    img=cv2.imread(img)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    x = np.asarray(img, dtype=float)\n",
    "    x=x/224\n",
    "    x= np.expand_dims(x,axis=0)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=preprocess_img(path+\"667626_18933d713e.jpg\")\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ResNet50(weights='imagenet',input_shape=(224,224,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_new = Model(model.input,model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=preprocess_img(path+\"667626_18933d713e.jpg\")\n",
    "img_vector=model_new.predict(img)\n",
    "print(img_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vector.reshape((-1,))\n",
    "print(img_vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_feature_extraction(img):\n",
    "    img=preprocess_img(img)\n",
    "    img_vector=model_new.predict(img)\n",
    "    img_vector=img_vector.reshape((-1,))\n",
    "    return img_vector\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=[]\n",
    "for i in descriptions:\n",
    "    key.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=train_test_split(key,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature={}\n",
    "for i in train:\n",
    "       image_feature[i]=image_feature_extraction(path+i+\".jpg\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"img_features.pkl\",\"wb\") as f:\n",
    "     pickle.dump(image_feature,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('img_features.pkl', 'rb') as f:\n",
    "  #  data = pickle.load(f)\n",
    "   # image_feature=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_feature_test={}\n",
    "for i in test:\n",
    "    image_feature_test[i]=image_feature_extraction(path+i+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"img_test_features.pkl\",\"wb\") as f:\n",
    "     pickle.dump(image_feature_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numtoword={}\n",
    "wordtonum={}\n",
    "\n",
    "for j,i in enumerate(total_words):\n",
    "    numtoword[j+1]=i\n",
    "    wordtonum[i]=j+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wordtonum))\n",
    "print(len(numtoword))\n",
    "total_len=len(wordtonum)+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtonum['startseq']=1846\n",
    "numtoword[1846]='startseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtonum['endseq']=1847\n",
    "numtoword[1847]='endseq'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=0\n",
    "for key in descriptions.keys():\n",
    "    for i in descriptions[key]:\n",
    "        maxlen=max(maxlen,len(i.split()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen+=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputdata(image_feature,descriptions,wordtonum,maxlen,batch_size):\n",
    "    X1,X2, y = [],[],[]\n",
    "    \n",
    "    n =0\n",
    "    while True:\n",
    "        for key in train.keys():\n",
    "            n += 1\n",
    "            \n",
    "            photo = image_feature[key]\n",
    "            for desc in descriptions[key] :\n",
    "                seq=[]\n",
    "                seq.append(wordtonum[\"startseq\"])\n",
    "                for word in desc.split():\n",
    "                      if(word in wordtonum):\n",
    "                        seq.append(wordtonum[word])\n",
    "                seq.append(wordtonum[\"endseq\"])\n",
    "                for i in range(0,len(seq)):\n",
    "                    xi = seq[0:i]\n",
    "                    yi = seq[i]\n",
    "                    \n",
    "                    #0 denote padding word\n",
    "                    xi = pad_sequences([xi],maxlen=maxlen,value=0,padding='post')[0]\n",
    "                    yi = to_categorical([yi],num_classes=total_len)[0]\n",
    "                    \n",
    "                    X1.append(photo)\n",
    "                    X2.append(xi)\n",
    "                    y.append(yi)\n",
    "                    \n",
    "                if n==batch_size:\n",
    "                    yield [[np.array(X1),np.array(X2)],np.array(y)]\n",
    "                    X1,X2,y = [],[],[]\n",
    "                    n = 0\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =open(\"glove.6B.50d.txt\",encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_index = {}\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    \n",
    "    word = values[0]\n",
    "    word_embedding = np.array(values[1:],dtype='float')\n",
    "    embedding_index[word] = word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index['and']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix():\n",
    "    emb_dim = 50\n",
    "    matrix = np.zeros((total_len,emb_dim))\n",
    "    for word,idx in wordtonum.items():\n",
    "        if embedding_index.get(word) is not None:\n",
    "            embedding_vector = embedding_index.get(word)\n",
    "            matrix[idx] = embedding_vector\n",
    "            \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = get_embedding_matrix()\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('embedding.txt', embedding_matrix, fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# image captioning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1 = Input(shape=(2048,))\n",
    "fe1 = Dropout(0.5)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "\n",
    "# partial caption sequence model\n",
    "inputs2 = Input(shape=(maxlen,))\n",
    "se1 = Embedding(total_len, 50, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.5)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "\n",
    "# decoder (feed forward) model\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(total_len, activation='softmax')(decoder2)\n",
    "\n",
    "# merge the two input models\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=Model(inputs=[input_img_features,input_captions],outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.layers[2].set_weights([embedding_matrix])\n",
    "final_model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(loss='categorical_crossentropy',optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 4\n",
    "steps = len(train)//6\n",
    "print(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epochs):\n",
    "        generator = inputdata(train,image_feature,image_feature_test,descriptions,wordtonum,maxlen,batch_size)\n",
    "        final_model.fit_generator(generator,epochs=1,steps_per_epoch=steps,verbose=1)\n",
    "        final_model.save('model_'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('3_model_9.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_caption(photo):\n",
    "    \n",
    "    in_text = \"startseq\"\n",
    "    for i in range(35):\n",
    "        sequence = [wordtonum[w] for w in in_text.split() if w in wordtonum]\n",
    "        sequence = pad_sequences([sequence],maxlen=35,padding='post')\n",
    "        \n",
    "        ypred = model.predict([photo,sequence])\n",
    "        ypred = ypred.argmax() #WOrd with max prob always - Greedy Sampling\n",
    "        word = numtoword[ypred]\n",
    "        in_text += (' ' + word)\n",
    "        \n",
    "        if word == \"endseq\":\n",
    "            break\n",
    "    \n",
    "    final_caption = in_text.split()[1:-1]\n",
    "    final_caption = ' '.join(final_caption)\n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=preprocess_img(path+\"755326139_ee344ece7b.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_vector=model_new.predict(img)\n",
    "print(img_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_caption(img_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
